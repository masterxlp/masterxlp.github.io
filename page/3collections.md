---
layout: page
title: Collections
permalink: /collection/
icon: bookmark
type: page
---

* content
{:toc}

## Blogs
### Multi-Task

* [多任务介绍](https://mp.weixin.qq.com/s/DSDkksVM89gZsbP37kpG3Q?)  
Deep Learning 回顾之多任务学习

## Paper
### Multi-Task
* [Unicorn: Continual learning with a universal, off-policy agent](https://arxiv.org/pdf/1802.08294)  
UVFA在多任务中的应用 + 终身学习

* [The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously](https://arxiv.org/abs/1707.03300)  
DDPG + Multi-task

* [Distral: Robust Multitask Reinforcement Learning](https://arxiv.org/abs/1707.04175)   
Distill & transfer learning

* [Universal Value Function Approximators](http://proceedings.mlr.press/v37/schaul15.pdf)  
通用值函数近似，对传统的值函数进行扩展，添加了目标作为输入

* [NEVER GIVE UP: LEARNING DIRECTED EXPLORATION STRATEGIES](https://arxiv.org/pdf/2002.06038)  
UVFA的扩展使用

### DeepMind
* [2015 - Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/pdf/1509.06461.pdf)

* [2015 - Massively Parallel Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1507.04296.pdf)

* [2015 - Learning Continuous Control Policies by Stochastic Value Gradients](https://arxiv.org/pdf/1510.09142.pdf)

* [2015 - Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning](https://arxiv.org/abs/1509.08731)

* [2016 - Increasing the Action Gap: New Operators for Reinforcement Learning](https://arxiv.org/abs/1512.04860)

* [2016 - Iterative Hierarchical Optimization for Misspecified Problems (IHOMP)](https://arxiv.org/abs/1602.03348)

* [2016 - Learning and Transfer of Modulated Locomotor Controllers](https://arxiv.org/abs/1610.05182)

* [2016 - Model-Free Episodic Control](https://arxiv.org/abs/1606.04460)

* [2016 - POLICY DISTILLATION](https://arxiv.org/abs/1511.06295)

* [2016 - Progressive Neural Networks](https://arxiv.org/abs/1606.04671)

* [2016 - Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971)

* [2016 - PRIORITIZED EXPERIENCE REPLAY](https://arxiv.org/abs/1511.05952)  
`优先级经验回放`

* [2016 - Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1602.01783)  
`A3C` -- 深度强化学习的异步方法

* [2016 - Continuous Deep Q-Learning with Model-based Acceleration](https://arxiv.org/abs/1603.00748)

* [2016 - Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/abs/1511.06581)  
`Dueling` - 深度强化学习的对抗神经网络结构

* [2016 - Deep Exploration via Bootstrapped DQN](https://arxiv.org/abs/1602.04621)

* [2016 - Learning to Communicate with Deep Multi-Agent Reinforcement Learning](https://arxiv.org/abs/1605.06676)

* [2016 - Learning values across many orders of magnitude](https://arxiv.org/abs/1602.07714)

* [2016 - Strategic Attentive Writer for Learning Macro-Actions](https://arxiv.org/abs/1606.04695)

* [2016 - Unifying Count-Based Exploration and Intrinsic Motivation](https://arxiv.org/abs/1606.01868)

* [2017 - Connecting Generative Adversarial Networks and Actor-Critic Methods](https://arxiv.org/abs/1610.01945)

* [2017 - Emergence of Locomotion Behaviours in Rich Environments](https://arxiv.org/abs/1707.02286)

* [2017 - Learning human behaviors from motion capture by adversarial imitation](https://arxiv.org/abs/1707.02201)

* [2017 - Learning model-based planning from scratch](https://arxiv.org/abs/1707.06170)

* [2017 - LEARNING TO REINFORCEMENT LEARN](https://arxiv.org/abs/1611.05763)

* [2017 - Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards](https://arxiv.org/abs/1707.08817)

* [2017 - The Intentional Unintentional Agent--Learning to Solve Many Continuous Control Tasks Simultaneously](https://arxiv.org/abs/1707.03300)

* [2017 - COMBINING POLICY GRADIENT AND Q-LEARNING](https://arxiv.org/abs/1611.01626)

* [2017 - RECURRENT ENVIRONMENT SIMULATORS](https://arxiv.org/abs/1704.02254)

* [2017 - SAMPLE EFFICIENT ACTOR-CRITIC WITH EXPERIENCE REPLAY](https://arxiv.org/abs/1611.01224)

* [2107 - A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887)

* [2017 - Count-Based Exploration with Neural Density Models](https://arxiv.org/abs/1703.01310)

* [2017 - DARLA: Improving Zero-Shot Transfer in Reinforcement Learning](https://arxiv.org/abs/1707.08475)

* [2017 - FeUdal Networks for Hierarchical Reinforcement Learning](https://arxiv.org/abs/1703.01161)

* [2017 - A multi-agent reinforcement learning model of common-pool resource appropriation](https://arxiv.org/abs/1707.06600)

* [2017 - A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning](https://arxiv.org/abs/1711.00832)

* [2017 - Distral: Robust Multitask Reinforcement Learning](https://arxiv.org/abs/1707.04175)  
`policy distill` 策略蒸馏

* [2017 - Imagination-Augmented Agents for Deep Reinforcement Learning](https://arxiv.org/abs/1707.06203)

* [2017 - Programmable Agents](https://arxiv.org/abs/1706.06383)

* [2017 - Robust Imitation of Diverse Behaviors](https://arxiv.org/abs/1707.02747)

* [2017 - Successor Features for Transfer in Reinforcement Learning](https://arxiv.org/abs/1606.05312)

* [2017 - LEARNING TO PERFORM PHYSICS EXPERIMENTS VIA DEEP REINFORCEMENT LEARNING](https://arxiv.org/abs/1611.01843)

* [2017 - REINFORCEMENT LEARNING WITH UNSUPERVISED AUXILIARY TASKS](https://arxiv.org/abs/1611.05397)

* [2018 - Rainbow- Combining Improvements in Deep Reinforcement Learning](https://arxiv.org/abs/1710.02298)

* [2018 - Value-Decomposition Networks For Cooperative Multi-Agent Learning](https://arxiv.org/abs/1706.05296)

* [2018 - Kickstarting Deep Reinforcement Learning](https://arxiv.org/abs/1803.03835)

* [2018 - Observe and Look Further: Achieving Consistent Performance on Atari](https://arxiv.org/abs/1805.11593)

* [2018 - Safe Exploration in Continuous Action Spaces](https://arxiv.org/abs/1801.08757)

* [2018 - Unicorn- Continual learning with a universal, off-policy agent](https://arxiv.org/abs/1802.08294)  
`UVFA` 的另一种结构 `Continual Learning` 终身学习

* [2018 - NOISY NETWORKS FOR EXPLORATION](https://arxiv.org/abs/1706.10295)

* [2018 - Learning to Search with MCTSnets](https://arxiv.org/abs/1802.04697)

* [2018 - Mix & Match – Agent Curricula for Reinforcement Learning](https://arxiv.org/abs/1806.01780)

* [2018 - More Robust Doubly Robust Off-policy Evaluation](https://arxiv.org/abs/1802.03493)

* [2018 - Progress & Compress: A scalable framework for continual learning](https://arxiv.org/abs/1805.06370)

* [2018 - The Uncertainty Bellman Equation and Exploration](https://arxiv.org/abs/1709.05380)

* [2018 - Meta-Gradient Reinforcement Learning](https://arxiv.org/abs/1805.09801)

* [2018 - Playing hard exploration games by watching YouTube](https://arxiv.org/abs/1805.11592)

* [2018 - Relational recurrent neural networks](https://arxiv.org/abs/1806.01822)

* [2018 - Learning by Playing – Solving Sparse Reward Tasks from Scratch](https://arxiv.org/abs/1802.10567)

* [2018 - Reinforcement and Imitation Learning for Diverse Visuomotor Skills](https://arxiv.org/abs/1802.09564)

* [2019 - SUCCESS AT ANY COST: VALUE CONSTRAINED MODEL-FREE CONTINUOUS CONTROL](https://openreview.net/pdf?id=rJlJ-2CqtX)

* [2019 - EMERGENT COORDINATION THROUGH COMPETITION](https://arxiv.org/abs/1902.07151)

* [2019 - LEARNING TO UNDERSTAND GOAL SPECIFICATIONS BY MODELLING REWARD](https://arxiv.org/abs/1806.01946)

* [2019 - Value Propagation Networks](https://arxiv.org/abs/1805.11199)

### On-policy to Off-policy

* [2018 - IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/abs/1802.01561)
`重要性权重`

## Comments

{% include comments.html %}
