I"ù<ul id="markdown-toc">
  <li><a href="#blogs" id="markdown-toc-blogs">Blogs</a>    <ul>
      <li><a href="#multi-task" id="markdown-toc-multi-task">Multi-Task</a></li>
    </ul>
  </li>
  <li><a href="#paper" id="markdown-toc-paper">Paper</a>    <ul>
      <li><a href="#multi-task-1" id="markdown-toc-multi-task-1">Multi-Task</a></li>
    </ul>
  </li>
  <li><a href="#comments" id="markdown-toc-comments">Comments</a></li>
</ul>

<h2 id="blogs">Blogs</h2>
<h3 id="multi-task">Multi-Task</h3>

<ul>
  <li><a href="https://mp.weixin.qq.com/s/DSDkksVM89gZsbP37kpG3Q?">å¤šä»»åŠ¡ä»‹ç»</a><br />
Deep Learning å›é¡¾ä¹‹å¤šä»»åŠ¡å­¦ä¹ </li>
</ul>

<h2 id="paper">Paper</h2>
<h3 id="multi-task-1">Multi-Task</h3>
<ul>
  <li>
    <p><a href="https://arxiv.org/pdf/1802.08294">Unicorn: Continual learning with a universal, off-policy agent</a><br />
UVFAåœ¨å¤šä»»åŠ¡ä¸­çš„åº”ç”¨ + ç»ˆèº«å­¦ä¹ </p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1707.03300">The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously</a><br />
DDPG + Multi-task</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1707.04175">Distral: Robust Multitask Reinforcement Learning</a> <br />
Distill &amp; transfer learning</p>
  </li>
  <li>
    <p><a href="http://proceedings.mlr.press/v37/schaul15.pdf">Universal Value Function Approximators</a><br />
é€šç”¨å€¼å‡½æ•°è¿‘ä¼¼ï¼Œå¯¹ä¼ ç»Ÿçš„å€¼å‡½æ•°è¿›è¡Œæ‰©å±•ï¼Œæ·»åŠ äº†ç›®æ ‡ä½œä¸ºè¾“å…¥</p>
  </li>
  <li></li>
</ul>

<h2 id="comments">Comments</h2>

:ET