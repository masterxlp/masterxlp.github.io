I"Ò<ul id="markdown-toc">
  <li><a href="#å‰è¨€" id="markdown-toc-å‰è¨€">å‰è¨€</a></li>
  <li><a href="#ç»¼è¿°" id="markdown-toc-ç»¼è¿°">ç»¼è¿°</a></li>
  <li><a href="#ç»å…¸è®ºæ–‡å‚è€ƒåˆ—è¡¨" id="markdown-toc-ç»å…¸è®ºæ–‡å‚è€ƒåˆ—è¡¨">ç»å…¸è®ºæ–‡å‚è€ƒåˆ—è¡¨</a></li>
</ul>

<h2 id="å‰è¨€">å‰è¨€</h2>

<p>è¿™æ˜¯ä¸€ç¯‡å…³äºå„ç»å…¸è®ºæ–‡å¯¹åŸºæœ¬çš„ <code class="highlighter-rouge">RL</code> è¿‡ç¨‹çš„æè¿°çš„ç»¼è¿°(ä¸ºäº†æ–¹ä¾¿è®°å¿†ç†è§£ï¼ŒåŒä¸€æ¦‚å¿µç»Ÿä¸€ç¬¦å·è¡¨ç¤º)ã€‚</p>

<h2 id="ç»¼è¿°">ç»¼è¿°</h2>

<p>æ ‡å‡†çš„å¼ºåŒ–å­¦ä¹ ï¼ˆ<code class="highlighter-rouge">Reinfocement Learning</code>ï¼‰æ˜¯ç”±æ™ºèƒ½ä½“ï¼ˆagentï¼‰</p>

<h2 id="ç»å…¸è®ºæ–‡å‚è€ƒåˆ—è¡¨">ç»å…¸è®ºæ–‡å‚è€ƒåˆ—è¡¨</h2>

<p><code class="highlighter-rouge">DQN</code>åŸæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning</a> <br />
<code class="highlighter-rouge">DDPG</code>åŸæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/abs/1509.02971">Continous Control with Deep Reinforcement Learning</a><br />
<code class="highlighter-rouge">A3C</code>åŸæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/abs/1602.01783">Asynchronous Methods for Deep Reinforcement Learning</a><br />
<code class="highlighter-rouge">HER</code>åŸæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/abs/1707.01495">Hindsight Experience Replay</a><br />
<code class="highlighter-rouge">UVFA</code>åŸæ–‡é“¾æ¥ï¼š<a href="http://proceedings.mlr.press/v37/schaul15.pdf">Universal Value Function Approximator</a></p>
:ET