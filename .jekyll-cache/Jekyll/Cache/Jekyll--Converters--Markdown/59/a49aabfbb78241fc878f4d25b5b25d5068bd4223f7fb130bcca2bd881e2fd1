I"<ul id="markdown-toc">
  <li><a href="#前言" id="markdown-toc-前言">前言</a></li>
  <li><a href="#综述" id="markdown-toc-综述">综述</a></li>
</ul>

<h2 id="前言">前言</h2>

<p>这是一篇关于各经典论文对基本的 <code class="highlighter-rouge">RL</code> 过程的描述的综述(为了方便记忆理解，同一概念统一符号表示)。</p>

<h2 id="综述">综述</h2>

<p>标准的强化学习（<code class="highlighter-rouge">Reinfocement Learning</code>） 是由智能体（<code class="highlighter-rouge">agent</code>）和环境（<code class="highlighter-rouge">enviroment</code>）组成的。智能体在离散的时间步下与环境进行交互；智能体与环境的一步交互过程可以被描述为：智能体首先观察环境的状态（<code class="highlighter-rouge">state</code>），然后智能体做出相应的动作（<code class="highlighter-rouge">action</code>）并作用于环境，最后智能体会接受到环境关于智能体所做动作的反馈，它包括环境的新的状态以及标量的奖励（<code class="highlighter-rouge">reward</code>）。<br />
<code class="highlighter-rouge">Note</code>：1. 智能体是根据策略（<code class="highlighter-rouge">Policy</code>）$\pi$ 来决定智能体在观察到状态</p>
:ET