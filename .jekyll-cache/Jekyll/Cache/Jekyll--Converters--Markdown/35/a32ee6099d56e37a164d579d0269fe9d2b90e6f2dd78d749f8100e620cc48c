I"Ò<ul id="markdown-toc">
  <li><a href="#è„‰ç»œåˆ†æ" id="markdown-toc-è„‰ç»œåˆ†æ">è„‰ç»œåˆ†æ</a></li>
  <li><a href="#æ¨¡å‹æµç¨‹å›¾" id="markdown-toc-æ¨¡å‹æµç¨‹å›¾">æ¨¡å‹æµç¨‹å›¾</a></li>
</ul>

<h2 id="è„‰ç»œåˆ†æ">è„‰ç»œåˆ†æ</h2>
<p>PPOè®ºæ–‡å®é™…ä¸Šæ—¶æå‡ºäº†ä¸€ä¸ª <code class="highlighter-rouge">clipped surrogate objective</code>ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜è¯¥ç›®æ ‡å‡½æ•°è¡¨ç°ç¡®å®ä¸é”™ï¼ˆå®é™…ä¸Šè¿˜æ˜¯åˆ†åœºæ™¯çš„ï¼‰ã€‚</p>

<p>ä» <strong>Policy Gradient</strong> å¼€å§‹ï¼Œå…¶ç›®æ ‡å‡½æ•°ä¸º \(L^{PG}(\theta) = \hat{\mathbb{E}}_t [log\pi_{\theta}(a_t|s_t)\hat{A}_t]\)ã€‚
ç›´è§‚åœ°ï¼Œå…¶ç­–ç•¥æ›´æ–°ä¾èµ–äº <strong>ç­–ç•¥</strong> $\pi(\theta)$ ä»¥åŠ <strong>ä¼˜åŠ¿å€¼</strong>  $\hat{A}_t$ã€‚
äº‹å®ä¸Šï¼Œç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„æ›´æ–°æ–¹å¼ä¸ºï¼šä¾æ®äºå½“å‰çš„ç­–ç•¥ï¼Œé€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ”¶é›†ä¸€æ‰¹æ•°æ®ï¼ŒåŸºäºè¿™æ‰¹æ•°æ®æ‰§è¡Œä¸€æ¬¡ç­–ç•¥æ›´æ–°ã€‚
å› æ­¤ï¼Œå®ƒå±äº <strong>on-policy</strong> çš„ç®—æ³•ã€‚
å¯¹äºon-policyçš„æ–¹æ³•ï¼Œå¦‚æœåˆ©ç”¨â€œæ—§â€æ•°æ®ï¼ˆ\(\pi_{old}\) æ”¶é›†åˆ°çš„æ ·æœ¬ï¼‰è¿›è¡Œç­–ç•¥æ›´æ–°ä¼šå¯¼è‡´ <strong>è¿‡å¤§çš„ç­–ç•¥æ›´æ–°</strong>ã€‚
é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆè¦ä½¿ç”¨ <strong>off-policy</strong> çš„æ–¹æ³•å‘¢ï¼Ÿ
è¿™æ˜¯å› ä¸º <strong>data efficiency</strong> çš„ç¼˜æ•…ï¼Œon-policyæ–¹æ³•å¯¹äºæ•°æ®çš„åˆ©ç”¨æ•ˆç‡å¤ªä½ã€‚</p>

<p>è€Œ <strong>Trust-Region Policy Optimization</strong> é€šè¿‡æ•°å­¦æ¨å¯¼æå‡ºäº†ä¸€ç§ <strong>surrogate objective</strong>ï¼Œè¿™ç§ç›®æ ‡å‡½æ•°åœ¨å¯¹ç­–ç•¥æ›´æ–°å¹…åº¦ä¸ŠåŠ ä»¥é™åˆ¶åï¼Œå¯ä»¥åšåˆ°ç­–ç•¥çš„å•è°ƒæå‡ã€‚
å…¶ç›®æ ‡å‡½æ•°ä¸º</p>

\[\begin{align}
\mathop{maximize}\limits_{\theta} \quad \hat{\mathbb{E}}_t [\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\hat{A}_t]
\end{align}\]

\[\begin{align}
subject\ to\ \hat{\mathbb{E}}_t [KL[\pi_{\theta_{old}}(\cdot|s_t), \pi_\theta(\cdot|s_t)]] \leq \delta
\end{align}\]

<p>è¿™æ˜¯ä¸€ä¸ªå¸¦çº¦æŸçš„ç›®æ ‡å‡½æ•°ï¼Œæ ¹æ®æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•å¯å°†å¸¦çº¦æŸçš„å‡½æ•°è½¬æ¢ä¸ºå¸¦æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼ˆæƒ©ç½šï¼‰çš„ç›®æ ‡å‡½æ•°ï¼š</p>

\[\begin{align}
\mathop{maximize}\limits_{\theta} \quad \hat{\mathbb{E}}_t [\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)} \hat{A}_t - \beta KL[\pi_{\theta_{old}}(\cdot|s_t), \pi_{\theta}(\cdot|s_t)]]
\end{align}\]

<p>ä½†æ˜¯åœ¨ç°å®ä¸­ï¼Œæˆ‘ä»¬æ— æ³•ç¡®å®šä¸€ä¸ªå›ºå®šçš„ $\beta$ æ¥é€‚åº”äºä¸åŒçš„ä»»åŠ¡ï¼Œç”šè‡³æ˜¯åŒä¸€ç§ä»»åŠ¡çš„ä¸åŒçŠ¶æ€ã€‚
ä½†æ˜¯ï¼ŒTRPOåˆæ‹¥æœ‰ä¸å¯å¤šå¾—çš„ä¼˜åŠ¿ï¼šå¯ä»¥guaranteeç­–ç•¥çš„ç¨³æ­¥ä¸Šå‡ï¼Œæˆ–è€…è‡³å°‘ä¸ä¼šä¸‹é™ã€‚</p>

<p>åŸºäºæ­¤ï¼Œæå‡ºäº†PPOæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å¯¹ <strong>probability ratio</strong> åŠ ä»¥æˆªæ–­ï¼Œå³é™åˆ¶ $r_t(\theta)$ çš„å¤§å°ï¼Œå½“ $r_t(\theta)$ ä½¿å¾—ç›®æ ‡å‡½æ•°å‡å°‘æ—¶ï¼Œæˆªæ–­å®ƒï¼Œä½¿å¾—ç›®æ ‡å‡½æ•°ä¸ä¼šå‡å°‘ã€‚
é€šè¿‡æˆªæ–­çš„æ–¹å¼è¾¾åˆ°ä¸TRPOç›¸åŒçš„æ•ˆæœï¼Œä½†æ˜¯å´æ¯”TRPOè¦æ›´ç®€å•ï¼Œå› ä¸ºå®ƒæ˜¯ä¼˜åŒ–ä¸€ä¸ªæ— çº¦æŸçš„ç›®æ ‡å‡½æ•°ã€‚
å…¶ç›®æ ‡å‡½æ•°ä¸ºï¼š</p>

\[\begin{align}
L^{CLIP}(\theta) = \hat{\mathbb{E}}_t [min(r_t(\theta) \hat{A}_t, clip(r_t(\theta), 1 - \epsilon, 1 + \epsilon) \hat{A}_t)]
\end{align}\]

<p>æ–‡ç« ä¸­é€šè¿‡å®éªŒè¯æ˜ï¼Œå½“ $\epsilon = 0.2$ æ—¶ï¼Œæ¨¡å‹æ€§èƒ½æœ€ä½³ã€‚</p>

<h2 id="æ¨¡å‹æµç¨‹å›¾">æ¨¡å‹æµç¨‹å›¾</h2>
<p>åŸºäºDeepMindçš„baselinesï¼Œç”»å‡ºäº†å…¶PPO2ç®—æ³•çš„æµç¨‹å›¾ï¼Œå¦‚ä¸‹ï¼š</p>
<div align="center"> ![Figure 1](../../../../image/ppoç½‘ç»œç»“æ„å›¾.png "ppo structure") </div>

<p>å¦ä¸€ç§attentionç»“æ„+maskæœºåˆ¶çš„PPOç®—æ³•æµç¨‹å›¾ï¼Œå¦‚ä¸‹ï¼š
<img src="../../../../image/alpha-star-ppoç½‘ç»œç»“æ„å›¾.png" alt="Figure 2" title="attention structure" /></p>
:ET