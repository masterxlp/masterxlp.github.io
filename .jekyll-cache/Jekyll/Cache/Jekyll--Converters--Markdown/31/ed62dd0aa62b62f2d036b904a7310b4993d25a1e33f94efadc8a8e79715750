I"<<p>转载自<a href="https://zhuanlan.zhihu.com/p/58226117">知乎</a></p>

<h2 id="impala-scalable-distributed-deep-rl-with-importance-weighted-actor-learner-architectures">IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures</h2>
<blockquote>
  <p>这篇文章提出了一个可用于大规模强化学习训练的框架 – IMPALA，其主要思想是通过大量的与训练无关的Actor来采集样本，将训练集中于Learner中，这样采样与训练便可以并行运行，
该框架具有较高的性能、较好的扩展性以及较高的数据效率。</p>
</blockquote>

<blockquote>
  <p>V-Trace 技术则是用来矫正由于采样与训练并行时导致的策略错位情况，通过V-Trace技术完成使用Off-Policy的样本进行训练的目的。</p>
</blockquote>
:ET