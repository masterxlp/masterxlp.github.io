I"Ȁ<h2 id="100-interview-questions-for-algorithm-engineer">100+ Interview Questions for Algorithm Engineer</h2>
<blockquote>
  <p>内容来源于 <strong>葫芦娃</strong> 编著的 <strong>百面机器学习</strong></p>
</blockquote>

<h3 id="01-特征归一化">01. 特征归一化</h3>
<blockquote>
  <p><code class="highlighter-rouge">目的</code>：为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，<strong>使得不同指标之间具有可比性</strong>。<br />
<code class="highlighter-rouge">栗子</code>：例如，分析一个人的身高和体重对健康的影响，如果使用米（m）和千克（kg）作为单位，那么身高特征会在 $1.6 \sim 1.8 m$ 的数值范围内，
体重特征会在 $50 \sim 100 kg$ 的返回内，这样 <strong>分析出来的结果显然会倾向于数值差别比较大的体重特征</strong>。<br />
<code class="highlighter-rouge">方法</code>：如果想要得到更为准确的结果，就需要进行 <strong>特征归一化（Normalization）</strong> 处理，使各指标处于同一数值量级，以便分析。</p>
</blockquote>

<h4 id="为什么需要对数值类型的特征做归一化">为什么需要对数值类型的特征做归一化？</h4>
<blockquote>
  <p>直观地，对数值类型的特征做归一化可以避免出现模型有偏的情况，使得各个特征之间可以相互比较、组合，得到更精准的、更值得信任的模型。</p>
</blockquote>

<p>我们不妨借助随机梯度下降的实例来说明归一化的重要性。
假设有两种数值类型的特征，$x_1$ 的取值范围为 $[0, 10]$，$x_2$ 的取值范围为 $[0, 3]$，
于是可以构造一个目标函数符合图1.1(a)中的等值图。</p>

<p>在学习速率相同的情况下，$x_1$ 的更新速度会大于 $x_2$，需要较多的迭代才能找到最优解。
如果将 $x_1$ 和 $x_2$ 归一化到相同的数值区间后，优化目标的等值图会变成图1.1(b)中的圆形，$x_1$ 和 $x_2$ 的更新速度变的更为一致，容易更快地通过梯度下降找到最优解。</p>

<div align="center"><img src="../image/数据归一化对梯度下降收敛速度产生的影响.png" width="50%" height="50%" /></div>
<div align="center">图1.1 数据归一化对梯度下降收敛速度产生的影响</div>

<p>当然，数据归一化并不是万能的。
在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回归、支持向量机、神经网络等模型。
但对于决策模型并不适用，以C4.5为例，决策树在进行节点分裂时主要依据数据集 \(D\) 关于特征 \(x\) 的信息增益比，而信息增益比跟特征是否经过归一化是无关的，因为归一化并不会改变样本在特征 \(x\) 上的信息增益。</p>

<h4 id="特征归一化的方法">特征归一化的方法</h4>
<blockquote>
  <p>对数值类型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内</p>
</blockquote>

<p>最常用的归一化方法主要有以下两种：</p>
<ul>
  <li>线性函数归一化（Min-Max Scaling）：它对原始数据进行线性变换，使结果映射到 $[0, 1]$ 的范围，实现对原始数据的等比例缩放。数学表达式如下，</li>
</ul>

\[\begin{align}
X_{norm} = \frac{X - X_{min}}{X_{max} - X_{min}} \tag{1.1}
\end{align}\]

<p>     其中 \(X\) 为原始数据，\(X_{max}\)、\(X_{min}\) 分别为原始数据中的最大值和最小值。</p>

<ul>
  <li>零均值归一化（Z-Score Normalization）：它会将原始数据映射到均值为0、标准差为1的正太分布上。具体来说，假设原始特征的均值为 \(\mu\)、标准差为 \(\sigma\)，那么归一化的数学表达式为：</li>
</ul>

\[\begin{align}
z = \frac{x - \mu}{\sigma} \tag{1.2}
\end{align}\]

<h3 id="02-类别型特征">02. 类别型特征</h3>
<blockquote>
  <p><code class="highlighter-rouge">定义</code>：类别型特征主要是指性别（男、女）、血型（A、B、AB、O）等 <strong>只在有限选项内取值的特征</strong>。<br />
类别型特征原始输入通常是字符串形式，除了决策树等少数模型能直接处理字符串形式的输入，对于逻辑回归、支持向量机等模型来说，类别型特征必须经过处理转换成数值型特征才能正确工作。</p>
</blockquote>

<h4 id="在对数据进行预处理时应该怎样处理类别型特征">在对数据进行预处理时，应该怎样处理类别型特征？</h4>
<ul>
  <li>
    <p>序号编码<br />
<strong>处理的数据类型</strong>：序号编码（Ordinal Encoding）通常用于<strong>处理类别间具有大小关系的数据</strong>。<br />
<strong>栗子</strong>：例如成绩，可以分为低、中、高三档，并且存在“高 &gt; 中 &gt; 低”的排序关系。<br />
<strong>说明</strong>：序号编码会按照大小关系对类别特征赋予一个数值 <strong>ID</strong>，例如高表示为3、中表示为2、低表示为1，<strong>转换后依然保留了大小关系</strong>。</p>
  </li>
  <li>独热编码<br />
<strong>处理的数据类型</strong>：独热编码（One-Hot Encoding）通常用于<strong>处理类别间不具有大小关系的特征</strong>。<br />
<strong>栗子</strong>：例如血型，一共有4个取值（A型血、B型血、AB型血、O型血），独热编码会把血型变成一个4维稀疏向量，A型血表示为 \((1, 0, 0, 0)\)，
B型血表示为 \(0, 1, 0, 0)\)，AB型血表示为 \((0, 0, 1, 0)\)，O型血表示为 \((0, 0, 0, 1)\)。<br />
<strong>说明</strong>：对于类别取值较多的情况下使用独热编码需要注意以下问题：
    <ul>
      <li><strong>使用稀疏向量来节省空间</strong>。在独热编码下，特征向量只有某一维取值为1，其他位置取值均为0。
  因此可以利用向量的稀疏表示有效地节省空间，并且目前大部分算法均接受稀疏向量形式的输入。</li>
      <li><strong>配合特征选择来降低维度</strong>。高维度特征会带来几方面的问题。一是在K近邻算法中，高维空间下两点之间的距离很难得到有效的衡量；
  二是在逻辑回归模型中，参数的数量会随着维度的增加而增加，容易引起过拟合问题；三是通常只有部分维度是对分类、预测有帮助，因此可以考虑配合特征选择来降低维度。</li>
    </ul>
  </li>
  <li>二进制编码<br />
<strong>处理过程</strong>：二进制编码主要分为两步，先用 <strong>序号编码</strong> 给每个类别赋予一个类别ID，然后将 <strong>类别ID对应的二进制编码</strong> 作为结果。<br />
<strong>栗子</strong>：以A、B、AB、O型血为例，表1.1是二进制编码的过程。<br />
A型血的ID为1，二进制表示为001；B型血的ID为2，二进制表示为010；以此类推可以得到AB型血和O型血的二进制表示。<br />
<strong>说明</strong>：可以看出，二进制编码本质上是利用二进制对ID进行哈希映射，最终得到 0/1 特征向量，且 <strong>维数少于独热编码，节省了存储空间</strong>。</li>
</ul>

<div align="center">表1.1 二进制编码和独热编码</div>

<table>
  <thead>
    <tr>
      <th style="text-align: center">                 </th>
      <th style="text-align: center">血型</th>
      <th style="text-align: center">类别ID</th>
      <th style="text-align: center">二进制表示</th>
      <th style="text-align: center">独热编码</th>
      <th style="text-align: center">                 </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">A</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0 0 1</td>
      <td style="text-align: center">1 0 0 0</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">B</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">0 1 0</td>
      <td style="text-align: center">0 1 0 0</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">AB</td>
      <td style="text-align: center">3</td>
      <td style="text-align: center">0 1 1</td>
      <td style="text-align: center">0 0 1 0</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">1 0 0</td>
      <td style="text-align: center">0 0 0 1</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<h3 id="03-高维组合特征的处理">03. 高维组合特征的处理</h3>
<blockquote>
  <p>在高维组合特征的问题中，往往面临着数量极为庞大的训练参数，导致要求的算力等代价极为巨大。
因此，在高维组合特征的问题中，一般会优先通过 <strong>降维的方式</strong> 将特征数量降低到一定的程度，再进行模型的拟合。</p>
</blockquote>

<h4 id="什么是高维组合特征如何处理高维组合特征">什么是高维组合特征？如何处理高维组合特征？</h4>
<p>为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。
以广告点击预估问题为例，原始数据有语言和类型两种离散特征，表1.2是语言和类型对点击的影响。
为了提高拟合能力，语言和类型可以组成二阶特征，表1.3是语言和类型组合特征对点击的影响。</p>

<div align="center">表1.2 语言和类型对点击的影响</div>

<table>
  <thead>
    <tr>
      <th style="text-align: center">                     </th>
      <th style="text-align: center">是否点击</th>
      <th style="text-align: center">语言</th>
      <th style="text-align: center">类型</th>
      <th style="text-align: center">                    </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">中文</td>
      <td style="text-align: center">电影</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">英文</td>
      <td style="text-align: center">电影</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">中文</td>
      <td style="text-align: center">电视剧</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">英文</td>
      <td style="text-align: center">电视剧</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<div align="center">表1.3 语言和类型的组合特征对点击的影响</div>

<table>
  <thead>
    <tr>
      <th style="text-align: center">是否点击</th>
      <th style="text-align: center">语言 = 中文  类型 = 电影</th>
      <th style="text-align: center">语言 = 中文  类型 = 电影</th>
      <th style="text-align: center">语言 = 英文  类型 = 电影</th>
      <th style="text-align: center">语言 = 中文  类型 = 电视剧</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
    </tr>
  </tbody>
</table>

<p>以逻辑回归为例，假设数据的特征向量为 $X = (x_1, x_2, \cdots, x_k)$，则有</p>

\[\begin{align}
Y = sigmoid(\sum_i \sum_j w_{ij} &lt;x_i, x_j&gt;) \tag{1.3}
\end{align}\]

<p>其中 $&lt;x_i, x_j&gt;$ 表示 $x_i$ 和 $x_j$ 的组合特征，$w_{ij}$ 的维度等于 $|x_i| \cdot |x_j|$，$|x_i|$ 和 $|x_j|$ 分别代表第 $i$ 个特征和第 $j$ 个特征不同取值的个数。
在表1.3的广告点击预测问题中，$w$ 的维度是 $2 \times 2 = 4$（语言取值为中文和英文两种、类型的取值为电影和电视剧两种）。
这种组合特征看起来是没有任何问题的，但当引入ID类型的特征时，问题就出现了。
以推荐问题为例，表1.4是用户ID和物品ID对点击的影响，表1.5是用户ID和物品ID的组合特征对点击的影响。</p>

<div align="center">表1.4 用户ID和物品ID对点击的影响</div>

<table>
  <thead>
    <tr>
      <th style="text-align: center">                     </th>
      <th style="text-align: center">是否点击</th>
      <th style="text-align: center">用户ID</th>
      <th style="text-align: center">物品ID</th>
      <th style="text-align: center">                    </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">m</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">m</td>
      <td style="text-align: center">n</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<div align="center">表1.5 用户ID和物品ID的组合特征对点击的影响</div>

<table>
  <thead>
    <tr>
      <th style="text-align: center">是否点击</th>
      <th style="text-align: center">用户ID = 1 物品ID = 1</th>
      <th style="text-align: center">用户ID = 2 物品ID = 1</th>
      <th style="text-align: center">…</th>
      <th style="text-align: center">用户ID = m 物品ID = 1</th>
      <th style="text-align: center">用户ID = 1 物品ID = 2</th>
      <th style="text-align: center">用户ID = 2 物品ID = 2</th>
      <th style="text-align: center">…</th>
      <th style="text-align: center">用户ID = m 物品ID = n</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">…</td>
      <td style="text-align: center">1</td>
    </tr>
  </tbody>
</table>

<p>若用户的数量为 $m$、物品的数量为 $n$，那么需要学习的参数的规模为 $m \times n$。
在互联网环境下，用户数量和物品数量都可以达到千万量级，几乎无法学习 $m \times n$ 规模的参数。
在这种情况下，一种行之有效的方法是将用户和物品分别用 $k$ 维的低向量表示（$k \ll m$，$k \ll n$），</p>

\[\begin{align}
Y = sigmoid(\sum_i \sum_j w_{ij} &lt;x_i, x_j&gt;) \tag{1.4}
\end{align}\]

<p>其中 $w_{ij} = x_{i}^{'} \cdot x_{j}^{'}$，$x_{i}^{'}$ 和 $x_{j}^{'}$ 分别表示 $x_i$ 和 $x_j$ 对应的低维向量。
在表1.5的推荐问题中，需要学习的参数的规模变为 $m \times k + n \times k$。
这其实就等价于 <strong>矩阵分解</strong>。</p>

<h3 id="04-组合特征">04. 组合特征</h3>
<blockquote>
  <p>在03节中我们介绍了如何利用降维方法来减少两个高维特征组合后需要学习的参数。
但是在很多实际问题中，我们常常需要面对多种高维特征。
如果只是简单地两两组合，依然容易存在参数过多以及过拟合等问题，而且并不是所有的特征组合都是有意义的。
因此，需要一种有效的方法来帮助我们找到应该对哪些特征进行组合。</p>
</blockquote>

<h4 id="怎么有效地找到组合特征">怎么有效地找到组合特征？</h4>
<blockquote>
  <p>本节介绍一种基于决策树的特征组合寻找方法</p>
</blockquote>

<p>以点击预测问题为例，假设原始输入特征包含年龄、性别、用户类型（试用期、付费）、物品类型（护肤、食品等）四个方面的信息，并且根据原始输入和标签（点击、未点击）构造出决策树，如图1.2所示。</p>

<div align="center"><img src="../image/基于决策树的特征组合方法.png" /></div>

<div align="center">图1.2 基于决策树的特征组合方法</div>

<p>于是，每一条从根节点到叶子结点的路径都可以看成一种特征组合的方式。
具体地，有以下4种特征组合的方式：</p>
<ul>
  <li>“年龄 &lt;= 35” 且 “性别 = 女”</li>
  <li>“年龄 &lt;= 35” 且 “物品类型 = 护肤”</li>
  <li>“用户类型 = 付费” 且 “物品类型 = 食品”</li>
  <li>“用户类型 = 付费” 且 “年龄 &lt;= 40”</li>
</ul>

<p>表1.6是两个样本的信息，那么第一个样本按照上述四种特征组合就可以编码为 $(1, 1, 0, 0)$，即满足第1、2个组合特征，但不满足第3、4个组合特征；
同理，第二个样本就可以编码为 $(0, 0, 1, 1)$，即满足第3、4个组合特征，但不满足第1、2个组合特征。</p>

<div align="center">表1.6 两个不同样本对应的原始输入特征</div>

<table>
  <thead>
    <tr>
      <th style="text-align: center">               </th>
      <th style="text-align: center">是否点击</th>
      <th style="text-align: center">年领</th>
      <th style="text-align: center">性别</th>
      <th style="text-align: center">用户类型</th>
      <th style="text-align: center">物品类型</th>
      <th style="text-align: center">               </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">是</td>
      <td style="text-align: center">28</td>
      <td style="text-align: center">女</td>
      <td style="text-align: center">免费</td>
      <td style="text-align: center">护肤</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">否</td>
      <td style="text-align: center">36</td>
      <td style="text-align: center">男</td>
      <td style="text-align: center">付费</td>
      <td style="text-align: center">食品</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<p>那么，再给定原始输入时，该如何有效地构造决策树呢？
我们可以利用 <strong>梯度提升决策树</strong>，该方法的思想是：每次都在之前构建的决策树的残差上构建下一颗决策树。</p>

<h3 id="05-文本表示模型">05. 文本表示模型</h3>
<blockquote>
  <p>文本是一类非常重要的非结构化数据，如何表示文本数据类型一直是机器学习领域的一个重要研究方向。</p>
</blockquote>

<h4 id="有哪些文本表示模型它们各有什么优缺点">有哪些文本表示模型？它们各有什么优缺点？</h4>
<h5 id="词袋模型和n-gram模型">词袋模型和n-gram模型</h5>
<p>最基础的文本表示模型就是词袋模型。
顾名思义，就是将每篇文章看成一袋子词，并忽略每个词出现的顺序。
具体地，将整段文本以词为单位切分开，然后每篇文章可以表示成一个长向量，向量中的每一维代表一个单词，而该维对应的权重则反映了这个词在原文章中的重要程度。
常用TF-IDF来计算权重，计算公式表示为</p>

\[\begin{align}
TF-IDF(t,d) = TF(t,d) \times IDF(t) \tag{1.5}
\end{align}\]

<p>其中 $TF(t,d)$ 表示单词 $t$ 在文档 $d$ 中出现的频率，$IDF(t)$ 表示逆文档频率，用来衡量单词 $t$ 对表达语义所起的重要性，表示为</p>

\[\begin{align}
IDF(t) = log \frac{文章总数}{包含单词t的文章总数 + 1} \tag{1.6}
\end{align}\]

<p>直观的解释是，如果一个词在非常多的文章中都出现的话，那么他可能就是一个比较通用的词汇，对于区分某篇文章的特殊语义的贡献较小，因此对权重做一定的惩罚。</p>

<p>有时候，将文章进行单词级别的划分并不是一种好的做法，比如英文中的 natural language processing 一词，如果将 natural、language、processing 这三个词拆分开来，
其所表示的含义与三个词连续出现时所表示的含义大相径庭。
通常，可以将连续出现的n个词（$n &lt;= N$）组成的词组（n-gram）也作为一个单独的特征放到向量表示中去，构成 n-gram 模型。
另外，同一个词可能有多种词性变化，却具有相似的含义。
在实际应用中，一般会对单词进行词干抽取（World Stemming）处理，即将不同词性的单词统一成同一词干的形式。</p>

<h5 id="主题模型">主题模型</h5>
<p>主题模型用于从文本库中发现代表性的主题（得到每个主题上词的分布特性），并且能够计算出每篇文章的主题分布。</p>

<h5 id="词嵌入与深度学习模型">词嵌入与深度学习模型</h5>
<p>词嵌入式一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间（通常 $K = 50 \sim 300$ 维）上的一个稠密向量（Dense Vector）。
$K$ 维空间的每一维也可以看作一个隐含的主题，只不过不像主题模型中的主题那样直观。</p>

<p>由于词嵌入将每个词映射成一个 $K$ 维向量，如果一片文档中有 $N$ 个词，就可以用 $N \times K$ 维的矩阵来表示这篇文档，但是这样的表示过于底层。
在实际应用中，如果仅仅把这个矩阵作为原文的表示特征输入到机器学习模型中，通常很难取到令人满意的结果。
因此，还需要在此基础上加工出更高层的特征。
在传统的浅层机器学习模型中，一个好的特征工作往往可以带来算法效果的显著提升。
而深度学习模型正好为我们提供了一种自动地进行特征工程的方式，模型中的每个隐层都可以认为对应着不同抽象层次的特征。
从这个角度来讲，深度学习模型能够打败浅层模型也就顺理成章了。
卷积神经网络和循环神经网络的结构在文本中取得了很好的效果，主要是由于它们能够更好的对文本进行建模，抽取出一些高层的语义特征。
与全连接神经网络结构相比，卷积神经网络和循环神经网络一方面能够很好的抓住我呢不能的特性，另一方面又减少了网络中带学习的参数的数量，提高了训练速度，并且降低了过拟合的风险。</p>

<h3 id="06-word2vec">06. Word2Vec</h3>
<blockquote>
  <p>谷歌2013年提出的 <strong>Word2Vec</strong> 是目前最常用的 <strong>词嵌入模型</strong> 之一。
Word2Vec 实际上是一种浅层的神经网络模型，它有两种网络结构：<code class="highlighter-rouge">CBOW</code>（Continues Bag of Words）和 <code class="highlighter-rouge">Skip-gram</code>。</p>
</blockquote>

<h4 id="word2vec是如何工作的">Word2Vec是如何工作的？</h4>
<p>CBOW的目标是根据上下文出现的词语来预测当前词的生成概率，如图1.3(a)所示；
而Skip-gram是根据当前词来预测上下文中各词的生成概率，如图1.3(b)所示。</p>

<div align="center"><img src="../image/Word2Vec的两种模型结构.png" /></div>

<div align="center">图1.3 Word2Vec的两种网络结构</div>

<p>其中 $w(t)$ 是当前所关注的词，$w(t-1)、w(t-2)、w(t+1)、w(t+2)$ 是上下文中出现的词。
这里前后滑动窗口的大小均设为2.</p>

<p>CBOW 和 Skip-gram 都可以表示成由输入层（Input）、映射层（Projection）以及输出层（Output）组成的神经网络。</p>

<p>输入层中的每个词由独热编码的方式表示，即所有词均表示成一个 $N$ 维向量，其中 $N$ 为词汇表中单词的总数。
在向量中，每个词都将与之对应的维度置为1，其余维度的值均为0.</p>

<p>在映射层（又称为隐含层）中，$K$ 个隐含单元（Hidden Units）的取值可以由 $N$ 维输入向量以及链接输入和隐含单元之间的 $N \times K$ 维的权重矩阵计算得到。
在CBOW中，还需要将各个输入词所计算出的隐含单元求和。</p>

<p>输出层向量的值可以通过隐含层向量（$K$ 维），以及连接隐含层和输出层之间的 $K \times N$ 维权重矩阵计算得到。
输出层也是一个 $N$ 维向量，每一维与词汇表中的一个单词相对应。
最后，对输出层向量应用softmax激活函数，可以计算出每个单词的生成概率。
Softmax激活函数的定义为</p>

\[\begin{align}
P(y = w_n|x) = \frac{e^{x_n}}{\sum_{k=1}^{N} e^{x_k}} \tag{1.7}
\end{align}\]

<p>其中 $x$ 代表 $N$ 维的原始输出向量，$x_n$ 为在原始输出向量中，与单词 $w_n$ 所对应维度的取值。</p>

<p>接下来的任务就是训练神经网络的权重，使得语料库中所有单词的整体生成概率最大化。
从输入层到隐含层需要一个维度为 $N \times K$ 的权重矩阵，学习权重可以用反向传播算法实现，每次迭代时将权重沿着更有的方向进行一小步的更新。
但是由于Softmax激活函数中存在归一化项的缘故，推导出来的迭代公式需要对词汇表中的所有单词进行遍历，使得每次迭代过程非常缓慢，由此产生了 Hierarchical Softmax 和 Negative Sampling 两种改进方法。
训练得到维度为 $N \times K$ 和 $K \times N$ 的两个权重矩阵之后，可以选择其中一个作为 $N$ 个词的 $K$ 维向量表示。</p>

<h4 id="它和lda有什么区别和联系">它和LDA有什么区别和联系？</h4>
<p>首先，LDA是利用 <strong>文档中单词的共现关系来</strong> 对单词按主题聚类，也可以理解为对“文档-单词”矩阵进行分解，得到“文档-主题”和“主题-单词”两个概率分布。
而Word2Vec其实是对“上下文-单词”矩阵进行学习，其中上下文由周围的几个单词组成，由此得到的词向量表示更多地 <strong>融入了上下文共现</strong> 的特征。
也就是说，如果两个单词所对应的Word2Vec向量相似度较高，那么它们很可能经常在同样的上下文中出现。
需要说明的是，上述分析的是LDA和Word2Vec的不同，不应该作为主题模型和词嵌入模型两类方法的主要差异。
主题模型通过一定的结构调整可以基于“上下文-单词”矩阵进行主题推理。
同样地，词嵌入方法也可以根据“文档-单词”矩阵学习出词的隐含向量表示。
主题模型和词嵌入两类方法最大的不同其实是模型本身，主题模型是一种基于概率图模型的生成式模型，其似然函数可以写成若干条件概率连乘的形式，其中包括需要推测的隐含变量（即主题）；
而词嵌入模型一般表达为神经网络形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得到单词的稠密向量表示。</p>

:ET